{
agent {
       exploration {
           epsilon_initial=1.0,
           epsilon_final=0.01,
           epsilon_steps=1000
           }
       training_episodes = 4000
       batch_size=128,
       gamma=0.9999,
       Polyak_averaging{
           tau_actor=0.01,
           tau_actor_param=0.001
           }
       learning_rate{
           actor=0.001,
           actor_param=0.0001
           }
       steps_before_learning=0,
       OU_noise=True,  # if false, uses epsilon-greedy with uniform-random action-parameter exploration
       clip_grad=10,
       inverting_gradients=True,
       zero_index_gradients=False,
       device="cpu",
       seed=None,
       actor_model {hidden_layers = [128]},
       actor_param_model {hidden_layers = [128]}
       }
}
